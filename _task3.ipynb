{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722a3f4-1f8e-4321-b240-ee3ded31a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helper_functions as hf\n",
    "import _task1 as _task1\n",
    "from ydata_quality import DataQuality\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0fbc3-0248-4d4d-8bb1-4c03b55627f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver method\n",
    "def init_task3():\n",
    "    integrationAndaggregationFunc()\n",
    "    sampleCleaningIdentifyingStrategies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d578416-6cc4-4e87-be5f-c29586472d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrationAndaggregationFunc():\n",
    "    ### READ IN THE 3 DATA SETS ###\n",
    "    # dataset containing some information on atuoscout240-data/manufacture from the files\n",
    "    dataset = _task1.preProcessingOfData()\n",
    "    # dataset containing information on returned orders\n",
    "    #returns = pd.read_excel('autoscout24-germany-dataset-merged.csv')\n",
    "    # dataset containing information on the managers for each region in the orders dataset\n",
    "    brands =  hf.readManufacturers()\n",
    "    datasetDfObj = pd.DataFrame(brands, columns=[ 'mark','country','year'])\n",
    "    datasetDfObj=datasetDfObj.astype({'mark': 'string', 'country': 'string', 'year':'int64'})\n",
    "\n",
    "    ###  Merge the datasets together ###\n",
    "\n",
    "    ###  Merge the datasets together ###\n",
    "    print('--------------------MERGING DATA-------------------------')\n",
    "\n",
    "    # merged_df = (dataset.merge(brands, how='left', on=['mark', 'country']))\n",
    "    merged_df=pd.merge(dataset, brands, how=\"right\", on=[\"mark\"])\n",
    "    merged_df.to_csv('autoscout24-germany-dataset-merged.csv', index=False)\n",
    "\n",
    "    print('Merged data output to data/output_data/merged_data.csv')\n",
    "    print('---------------------------------------------------------')\n",
    "\n",
    "    ### FILTERING EXAMPLES ###\n",
    "    print('----------FILTERING EXAMPLE 1: NOT RETURNED--------------')\n",
    "\n",
    "    #not_returned_df = merged_df.loc[merged_df['country'].isna(), :]\n",
    "    not_returned_df=merged_df.dropna()\n",
    "\n",
    "    #not_returned_df.to_csv('autoscout24-germany-dataset-merged-filtered.csv', index=False)\n",
    "\n",
    "    print('Result output to autoscout24-germany-dataset-merged-filtered.csv')\n",
    "    print('---------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "    ### AGGREGATION?GROUPBY EXAMPLES ###\n",
    "\n",
    "    print('----------AGGREGATION EXAMPLE 1: MEAN()-----------------')\n",
    "\n",
    "    agg_example_1 = not_returned_df.groupby(by='country')['price'].mean()\n",
    "\n",
    "    print(agg_example_1)\n",
    "\n",
    "    print('---------------------------------------------------------')\n",
    "\n",
    "\n",
    "    print('------------AGGREGATION EXAMPLE 2: AGG()-----------------')\n",
    "\n",
    "    agg_example_2 = not_returned_df.groupby(by='country').agg({'mileage':'mean','year_x':'median'})\n",
    "\n",
    "    print(agg_example_2)\n",
    "\n",
    "    print('---------------------------------------------------------')\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182c034-6ff2-4237-9b80-2fc2ed2f4309",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Mostrimi, pastrimi, identifikimi dhe strategjia e trajtimit për vlerat e zbrazëta\n",
    "def sampleCleaningIdentifyingStrategies():\n",
    "    filteredDataset =  hf.readMergedDataset()\n",
    "    # generating one row \n",
    "    sample1 = filteredDataset.sample(n = 5)  \n",
    "    # display\n",
    "    print(sample1)\n",
    "\n",
    "    # generating another row\n",
    "    sample2 = filteredDataset.sample(frac =.25)\n",
    "    # display\n",
    "    print(sample2)\n",
    "\n",
    "    print('Checking if sample is 0.25 times data or not')\n",
    "    if (0.25*(len(filteredDataset))== len(sample2)):\n",
    "        print( \"Checked, sample is 0.25 times data!\")\n",
    "        print(len(filteredDataset), len(sample2))\n",
    "\n",
    "    # Chose how many index include for random selection\n",
    "    chosen_idx = np.random.choice(4, replace = True, size = 6)\n",
    "    print(filteredDataset.iloc[chosen_idx])    \n",
    "    hf.missing_cols(filteredDataset)\n",
    "\n",
    "    print('\\n Decsibe filter dataset for price')\n",
    "    filteredDataset['price'].describe()\n",
    "\n",
    "    print('\\n In this histogram, you can see that most of the data is around 0 to 5000')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    filteredDataset['price'].hist(bins=100)\n",
    "\n",
    "    print('\\n As you can see, the price column has multiple data points that are outliers (above of the maximum in the boxplot)')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    filteredDataset.boxplot(column=['price'])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    filteredDataset['mark'].value_counts().plot.bar()\n",
    "    print(filteredDataset.isnull())\n",
    "    filteredDataset1 = filteredDataset[filteredDataset.isna().any(axis=1)]\n",
    "    print(filteredDataset1)\n",
    "\n",
    "    print('\\n Clean up filtered dataset, deleted null values')\n",
    "    filteredDataset=filteredDataset.dropna()\n",
    "    hf.missing_cols(filteredDataset)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf596d6-5b43-4197-967e-327239471101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data inside dataFrame, and treate data\n",
    "def cleanCarDataSet():\n",
    "    data = hf.readDataset()\n",
    "    # fill missing data\n",
    "    print(\"Treating missing values\")\n",
    "    data[\"model\"].fillna('Unknown', inplace=True)\n",
    "    data[\"gear\"].fillna('Unknown', inplace=True)\n",
    "    data[\"hp\"].fillna('0', inplace=True)\n",
    "\n",
    "    #drop rows that are duplicates\n",
    "    print(\"Duplicate Rows :\")\n",
    "    print(data.duplicated())\n",
    "    print(data.duplicated().sum())\n",
    "    print(\"Removing duplicates....\")\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    print(data.duplicated().sum())\n",
    "    print(\"Duplicates removed successfully!\")\n",
    "\n",
    "    print(\"Dataset column type definition in process...\\n\")\n",
    "    # defining column types: mileage,make,model,fuel,gear,offerType,price,hp,year\n",
    "    data['mileage'] = data['mileage'].astype(float)\n",
    "    data['make'] = data['make'].astype(\"string\")\n",
    "    data['model'] = data['model'].astype(\"string\")\n",
    "    data['fuel'] = data['fuel'].astype(\"string\")\n",
    "    data['gear'] = data['gear'].astype(\"string\")\n",
    "    data['offerType'] = data['model'].astype(\"string\")\n",
    "    data['price'] = data['mileage'].astype(float)\n",
    "    data['hp'] = data['mileage'].astype(int)\n",
    "    data['year'] = data['fuel'].astype(\"string\")\n",
    "\n",
    "    # fill missing data and transforming data addin , at thousand seperator\n",
    "    #data['millage'] = f'{data['millage']:,}'\n",
    "\n",
    "    print(\"Dataset has successfully gone into the proccess of cleaning.\\n\")\n",
    "\n",
    "    return data\n",
    "\n",
    "cleanCarDataSet()\n",
    "\n",
    "data = hf.readDataset()\n",
    "#We check if we have both unkonwn values in make and model, because they'd be useless for us\n",
    "sameMakeAndModel = data['make'] == data['model']\n",
    "print(sameMakeAndModel)\n",
    "sameMakeAndModel[sameMakeAndModel.astype(str).str.contains('True') ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
